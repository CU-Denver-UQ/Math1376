{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math  1376: Programming for Data Science\n",
    "---\n",
    "\n",
    "## Assignment 03 (for part c): How to test your functions and modules (due by 11:59 p.m. Friday of week 6 of class)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Introducing [doctest](https://docs.python.org/3.8/library/doctest.html)\n",
    "---\n",
    "\n",
    "The documentation for a [`doctest`](https://docs.python.org/3.8/library/doctest.html) is probably most useful to review after seeing a simple example. There are other Python modules available for testing your code such as [`unittest`](https://docs.python.org/3/library/unittest.html?highlight=unittest#module-unittest), but we will primarily focus on `doctest` for its simplicity in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The value of testing\n",
    "---\n",
    "\n",
    "Here, we briefly discuss the value of constructing tests for your code. This also reinforces the importance of documenting code as discussed in the lecture.\n",
    "\n",
    "The value of testing becomes apparent once we realize that coding is often an iterative process in practice that typically \"stitches\" together lots of different \"pieces\" to make a more useful \"whole.\" \n",
    "Over time, individual pieces will be updated to improve functionality or fix issues that arise in operation. \n",
    "Common goals for improved functionality are to increase the speed of computations, allow for more flexible processing of data types, improved handling of \"edge cases\" (i.e., inputs that may \"break\" the original code in some way or given unexpected outputs), or providing new and useful features as the user-base or use-cases for the code mature. \n",
    "It is therefore critically important to make sure that these individual pieces are actually functioning correctly both prior to and following any updates. \n",
    "This is where testing comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The purpose of `doctest` vs `unittest`\n",
    "---\n",
    "\n",
    "- The basic purpose of `doctest` is to perform tests written into your documentation of a function that demonstrate *typical use cases.* \n",
    "<br><br>\n",
    "    - The tests should be simple and useful to someone trying to  understand what the function does.\n",
    "    <br><br>\n",
    "- The basic purpose of `unittest` is to perform tests that are more \"diagnostic\" in nature to ensure that nothing \"broke\" in the code when either it or other parts of the code it may depend upon were updated. \n",
    "<br><br>\n",
    "\n",
    "Consequently, I would say that unit tests are meant to be *thorough* whereas doc tests are meant to be *illuminating*. These are just my opinions though. You should formulate your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A suggestion\n",
    "---\n",
    "\n",
    "You should probably spend 15-20 minutes reading more about testing and why it is useful. There are lots of blogs and articles written about unit testing. Find some on Google. There is actually a nice discussion about the built-in Python modules `doctest` and `unittest` on [stackoverflow](https://stackoverflow.com/questions/361675/python-doctest-vs-unittest). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without further ado...\n",
    "---\n",
    "\n",
    "We now dive into it. Run the code cells below and interpret what is happening in the Markdown cell that follows. To truly understand what is happening, you may need to try editing the tests so that they *fail*, add new tests for yourself, etc. Play around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    '''\n",
    "    This function adds a to b. Why do we need a function to do that?\n",
    "    We don't. No reason. But, it is useful for illustrating how to use\n",
    "    the doctest feature. \n",
    "    \n",
    "    This is a test:\n",
    "    >>> add(2, 2)\n",
    "    4\n",
    "    \n",
    "    The above was a test. If we wanted to have more tests, then we could\n",
    "    add some more. Notice the formatting requirements.\n",
    "    \n",
    "    We should also test that:\n",
    "    >>> add(3,5)\n",
    "    8\n",
    "    \n",
    "    >>> add(105.5, 0.5)\n",
    "    106.0\n",
    "    '''\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_strings(a, b):\n",
    "    '''\n",
    "    What if I want to add a and b as if they were strings?\n",
    "    \n",
    "    >>> add_strings(2, 2)\n",
    "    '22'\n",
    "    \n",
    "    >>> add_strings(3,5)\n",
    "    '35'\n",
    "    \n",
    "    >>> add_strings(105.5, 0.5)\n",
    "    '105.50.5'\n",
    "    '''\n",
    "    return add(str(a), str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.testmod(verbose=True) #This may be too much if we only want to test the add_strings function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.run_docstring_examples(add_strings, globs=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> YOUR EXPLANATION FOR THE ABOVE CODE CELLS GOES HERE.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,0,255, 0.25); color:black'> JUST IN CASE YOU DID NOT EXPERIMENT WITH A FAILED TEST.</span>\n",
    "\n",
    "If you did not experiment much with the above code cells, then consider the code cells below that show a failed test. If a test failed, this does not necessarily mean that the test is bad. While it may be the case that a failed test is due to a poorly written test, a good test *should* fail when the code has something *wrong* with it. A failed test basically means that the test is doing what it should. It is detecting possible errors in the code that should be fixed before the code is deployed to other users.\n",
    "\n",
    "In fact, the best thing a test can do for you is *fail* even if the code does not produce any errors. \n",
    "It is possible for code to execute but give unexpected/undesirable outputs.\n",
    "Catching these with tests can save you (and the users of your code) a lot of frustration.\n",
    "\n",
    "So, run the code cells below, explain what is going on in the Markdown cell, and explain what needs to be fixed in the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is\n",
    "def weird_combo(a, b):\n",
    "    '''\n",
    "    We treat a and b as strings.\n",
    "    First, we add a to the first character in b.\n",
    "    Second, we add b to the last character in a.\n",
    "    Finally, we return the sum of these two results.\n",
    "    \n",
    "    >>> weird_combo(31, 24)\n",
    "    '312241'\n",
    "    '''\n",
    "    \n",
    "    first = add(str(a), str(b)[0])\n",
    "    second = add(str(a)[-1], str(b))\n",
    "                 \n",
    "    return add(first, second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.run_docstring_examples(weird_combo, globs=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> YOUR EXPLANATION FOR THE ABOVE CODE CELLS GOES HERE.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Population model and doctest\n",
    "---\n",
    "\n",
    "We revisit the population model from the previous assignment.\n",
    "\n",
    "(a) **This can be copied from your solutions to the previous assignment:** Use the Markdown cell below to summarize the population growth model and its solution described here: https://en.wikipedia.org/wiki/Logistic_function#In_ecology:_modeling_population_growth\n",
    "\n",
    "In the previous assignment, you were asked to (i) Code the solution function to take keyword arguments for the model parameters $r$, $P_0$, and $K$ (described in your Markdown cell) as well as for the time $t$ for which the solution is to be evaluated, and (ii) evaluate this function with $r=0.01$, $P_0=1$, $K=2$, at $t = 1, 10, 100$, and $1000$ and print results. Then, make $r=0.5$ and repeat. \n",
    "\n",
    "(b) Code the solution function to take keyword arguments for the model parameters $r$, $P_0$, and $K$ (described in your Markdown cell) as well as for the time $t$ for which the solution is to be evaluated. Make sure to use a docstring to describe the solution function and add at least two tests in the docstring based on easily computed inputs and at least two tests in the docstring based on the values from the previous assignment.\n",
    "\n",
    "(c) Use `doctest` to test your function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> SUMMARY FOR PART (a) GOES HERE.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code solution function for part (b) here with docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use doctest here for part (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Testing the `differences` module from the lecture\n",
    "---\n",
    "\n",
    "Run the code below. Fix the failed tests and add docstrings with useful tests to all the functions in the module. Show that all your tests pass. Summarize your work in a Markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import differences as diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.testmod(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> YOUR EXPLANATION FOR THE ABOVE CODE CELLS GOES HERE.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Testing your module from the lecture\n",
    "---\n",
    "\n",
    "Create some doc tests for the module you created as an activity at the end of the lecture. Show that they work in a code cell below. Summarize your work in a Markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> YOUR EXPLANATION FOR THE ABOVE CODE CELLS GOES HERE.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
